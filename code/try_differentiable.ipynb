{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import PcapDataset\n",
    "from constants import PCAP_PATH\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAP_PATH = \"../data/benign/weekday.pcap\"\n",
    "CSV_PATH  = \"../data/benign/weekday.csv\"\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size) -> None:\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        trx = x.reshape(1, 1, x.shape[-1]).to(torch.float)\n",
    "        _, (hidden, _) = self.lstm(trx)  # Use the last hidden state for prediction\n",
    "        out = self.linear(hidden[-1])\n",
    "        return out\n",
    "# Instantiate the model with specified dimensions\n",
    "model = LSTM(input_size=235, hidden_size=64, num_layers=2, output_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subrat/anaconda3/envs/panda/lib/python3.10/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([1, 100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, packets \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Define loss function and optimizer\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(packets)\n\u001b[0;32m---> 15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy())\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat))\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/panda/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/panda/lib/python3.10/site-packages/pandas/core/indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/panda/lib/python3.10/site-packages/pandas/core/indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Load feature vectors from CSV file\n",
    "features = pd.read_csv(CSV_PATH).iloc[:, :-2]\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Create the dataset\n",
    "    dataset = PcapDataset(pcap_file=PCAP_PATH, max_iterations=sys.maxsize)\n",
    "\n",
    "    # Create the DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    for i, packets in enumerate(dataloader):\n",
    "        # Define loss function and optimizer\n",
    "        outputs = model(packets)\n",
    "        loss = criterion(outputs, torch.from_numpy(features.iloc[i].to_numpy()).to(torch.float))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print training progress\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 9.6000e+01, 0.0000e+00, 1.0000e+00, 9.6000e+01, 0.0000e+00,\n",
       "        1.0000e+00, 9.6000e+01, 0.0000e+00, 1.0000e+00, 9.6000e+01, 0.0000e+00,\n",
       "        1.0000e+00, 9.6000e+01, 0.0000e+00, 1.0000e+00, 9.6000e+01, 0.0000e+00,\n",
       "        0.0000e+00, 1.1015e+02, 0.0000e+00, 0.0000e+00, 1.0000e+00, 9.6000e+01,\n",
       "        0.0000e+00, 0.0000e+00, 1.1015e+02, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        9.6000e+01, 0.0000e+00, 0.0000e+00, 1.1015e+02, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 9.6000e+01, 0.0000e+00, 9.0949e-13, 1.1015e+02, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 9.6000e+01, 0.0000e+00, 0.0000e+00, 1.1015e+02,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        9.6000e+01, 0.0000e+00, 0.0000e+00, 9.6000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 9.6000e+01, 0.0000e+00, 0.0000e+00, 9.6000e+01, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 9.6000e+01, 0.0000e+00, 0.0000e+00, 9.6000e+01,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 9.6000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        9.6000e+01, 0.0000e+00, 0.0000e+00, 1.0000e+00, 9.6000e+01, 0.0000e+00,\n",
       "        0.0000e+00, 9.6000e+01, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv(CSV_PATH).iloc[:, :-2]\n",
    "torch.from_numpy(features.iloc[1].to_numpy()).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HT_MI_5_weight</th>\n",
       "      <th>HT_MI_5_mean</th>\n",
       "      <th>HT_MI_5_std</th>\n",
       "      <th>HT_MI_3_weight</th>\n",
       "      <th>HT_MI_3_mean</th>\n",
       "      <th>HT_MI_3_std</th>\n",
       "      <th>HT_MI_1_weight</th>\n",
       "      <th>HT_MI_1_mean</th>\n",
       "      <th>HT_MI_1_std</th>\n",
       "      <th>HT_MI_0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HT_Hp_0.1_magnitude</th>\n",
       "      <th>HT_Hp_0.1_covariance</th>\n",
       "      <th>HT_Hp_0.1_pcc</th>\n",
       "      <th>HT_Hp_0.01_weight</th>\n",
       "      <th>HT_Hp_0.01_mean</th>\n",
       "      <th>HT_Hp_0.01_std</th>\n",
       "      <th>HT_Hp_0.01_radius</th>\n",
       "      <th>HT_Hp_0.01_magnitude</th>\n",
       "      <th>HT_Hp_0.01_covariance</th>\n",
       "      <th>HT_Hp_0.01_pcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.999384</td>\n",
       "      <td>91.498613</td>\n",
       "      <td>20.249998</td>\n",
       "      <td>1.999630</td>\n",
       "      <td>91.499168</td>\n",
       "      <td>20.249999</td>\n",
       "      <td>1.999877</td>\n",
       "      <td>91.499723</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>1.999988</td>\n",
       "      <td>...</td>\n",
       "      <td>91.499972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.999999</td>\n",
       "      <td>91.499997</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>91.499997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.917074</td>\n",
       "      <td>64.954193</td>\n",
       "      <td>110.043709</td>\n",
       "      <td>1.949386</td>\n",
       "      <td>64.772624</td>\n",
       "      <td>110.175676</td>\n",
       "      <td>1.982836</td>\n",
       "      <td>64.590893</td>\n",
       "      <td>110.241738</td>\n",
       "      <td>1.998270</td>\n",
       "      <td>...</td>\n",
       "      <td>118.309953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>118.309972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.835460</td>\n",
       "      <td>71.671202</td>\n",
       "      <td>154.046528</td>\n",
       "      <td>2.899159</td>\n",
       "      <td>71.404677</td>\n",
       "      <td>155.705889</td>\n",
       "      <td>2.965658</td>\n",
       "      <td>71.135514</td>\n",
       "      <td>157.262148</td>\n",
       "      <td>2.996532</td>\n",
       "      <td>...</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>64.390300</td>\n",
       "      <td>58.551943</td>\n",
       "      <td>1444.491701</td>\n",
       "      <td>71.245826</td>\n",
       "      <td>61.677086</td>\n",
       "      <td>3357.467390</td>\n",
       "      <td>85.315213</td>\n",
       "      <td>88.203451</td>\n",
       "      <td>31338.731422</td>\n",
       "      <td>155.374384</td>\n",
       "      <td>...</td>\n",
       "      <td>1456.919742</td>\n",
       "      <td>-1125.076738</td>\n",
       "      <td>-0.090714</td>\n",
       "      <td>76.962076</td>\n",
       "      <td>64.486558</td>\n",
       "      <td>4025.863982</td>\n",
       "      <td>40551.972963</td>\n",
       "      <td>1455.855829</td>\n",
       "      <td>-4200.761291</td>\n",
       "      <td>-0.329585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>65.320267</td>\n",
       "      <td>58.482256</td>\n",
       "      <td>1422.690064</td>\n",
       "      <td>72.199322</td>\n",
       "      <td>61.570754</td>\n",
       "      <td>3311.769647</td>\n",
       "      <td>86.296647</td>\n",
       "      <td>87.807104</td>\n",
       "      <td>30988.979572</td>\n",
       "      <td>156.371003</td>\n",
       "      <td>...</td>\n",
       "      <td>1456.913885</td>\n",
       "      <td>-1122.440902</td>\n",
       "      <td>-0.091074</td>\n",
       "      <td>77.961908</td>\n",
       "      <td>64.352049</td>\n",
       "      <td>3975.617564</td>\n",
       "      <td>40547.015494</td>\n",
       "      <td>1455.849877</td>\n",
       "      <td>-4188.699383</td>\n",
       "      <td>-0.330709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>66.272302</td>\n",
       "      <td>58.414622</td>\n",
       "      <td>1401.521302</td>\n",
       "      <td>73.167508</td>\n",
       "      <td>61.467283</td>\n",
       "      <td>3267.279452</td>\n",
       "      <td>87.283969</td>\n",
       "      <td>87.419780</td>\n",
       "      <td>30646.887504</td>\n",
       "      <td>157.368705</td>\n",
       "      <td>...</td>\n",
       "      <td>1456.908190</td>\n",
       "      <td>-1119.810009</td>\n",
       "      <td>-0.091428</td>\n",
       "      <td>78.961793</td>\n",
       "      <td>64.220947</td>\n",
       "      <td>3926.608927</td>\n",
       "      <td>40542.239555</td>\n",
       "      <td>1455.844088</td>\n",
       "      <td>-4176.699969</td>\n",
       "      <td>-0.331813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>67.238578</td>\n",
       "      <td>58.348966</td>\n",
       "      <td>1380.962832</td>\n",
       "      <td>74.145166</td>\n",
       "      <td>61.366571</td>\n",
       "      <td>3223.955371</td>\n",
       "      <td>88.275084</td>\n",
       "      <td>87.041194</td>\n",
       "      <td>30312.221632</td>\n",
       "      <td>158.367103</td>\n",
       "      <td>...</td>\n",
       "      <td>1456.902648</td>\n",
       "      <td>-1117.184313</td>\n",
       "      <td>-0.091777</td>\n",
       "      <td>79.961713</td>\n",
       "      <td>64.093124</td>\n",
       "      <td>3878.792948</td>\n",
       "      <td>40537.636403</td>\n",
       "      <td>1455.838455</td>\n",
       "      <td>-4164.762776</td>\n",
       "      <td>-0.332898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>204.978781</td>\n",
       "      <td>1471.337290</td>\n",
       "      <td>17449.840889</td>\n",
       "      <td>218.193356</td>\n",
       "      <td>1466.525953</td>\n",
       "      <td>24017.461670</td>\n",
       "      <td>232.938521</td>\n",
       "      <td>1459.641027</td>\n",
       "      <td>33350.245177</td>\n",
       "      <td>240.170676</td>\n",
       "      <td>...</td>\n",
       "      <td>1457.021201</td>\n",
       "      <td>-1114.571229</td>\n",
       "      <td>-0.091750</td>\n",
       "      <td>245.922117</td>\n",
       "      <td>1454.547179</td>\n",
       "      <td>40191.099793</td>\n",
       "      <td>40377.834728</td>\n",
       "      <td>1455.958593</td>\n",
       "      <td>-4152.895061</td>\n",
       "      <td>-0.332612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HT_MI_5_weight  HT_MI_5_mean   HT_MI_5_std  HT_MI_3_weight  \\\n",
       "0            1.000000     54.000000      0.000000        1.000000   \n",
       "1            1.000000     96.000000      0.000000        1.000000   \n",
       "2            1.999384     91.498613     20.249998        1.999630   \n",
       "3            1.917074     64.954193    110.043709        1.949386   \n",
       "4            2.835460     71.671202    154.046528        2.899159   \n",
       "...               ...           ...           ...             ...   \n",
       "19995       64.390300     58.551943   1444.491701       71.245826   \n",
       "19996       65.320267     58.482256   1422.690064       72.199322   \n",
       "19997       66.272302     58.414622   1401.521302       73.167508   \n",
       "19998       67.238578     58.348966   1380.962832       74.145166   \n",
       "19999      204.978781   1471.337290  17449.840889      218.193356   \n",
       "\n",
       "       HT_MI_3_mean   HT_MI_3_std  HT_MI_1_weight  HT_MI_1_mean   HT_MI_1_std  \\\n",
       "0         54.000000      0.000000        1.000000     54.000000      0.000000   \n",
       "1         96.000000      0.000000        1.000000     96.000000      0.000000   \n",
       "2         91.499168     20.249999        1.999877     91.499723     20.250000   \n",
       "3         64.772624    110.175676        1.982836     64.590893    110.241738   \n",
       "4         71.404677    155.705889        2.965658     71.135514    157.262148   \n",
       "...             ...           ...             ...           ...           ...   \n",
       "19995     61.677086   3357.467390       85.315213     88.203451  31338.731422   \n",
       "19996     61.570754   3311.769647       86.296647     87.807104  30988.979572   \n",
       "19997     61.467283   3267.279452       87.283969     87.419780  30646.887504   \n",
       "19998     61.366571   3223.955371       88.275084     87.041194  30312.221632   \n",
       "19999   1466.525953  24017.461670      232.938521   1459.641027  33350.245177   \n",
       "\n",
       "       HT_MI_0.1_weight  ...  HT_Hp_0.1_magnitude  HT_Hp_0.1_covariance  \\\n",
       "0              1.000000  ...            54.000000              0.000000   \n",
       "1              1.000000  ...            96.000000              0.000000   \n",
       "2              1.999988  ...            91.499972              0.000000   \n",
       "3              1.998270  ...           118.309953              0.000000   \n",
       "4              2.996532  ...            84.000000              0.000000   \n",
       "...                 ...  ...                  ...                   ...   \n",
       "19995        155.374384  ...          1456.919742          -1125.076738   \n",
       "19996        156.371003  ...          1456.913885          -1122.440902   \n",
       "19997        157.368705  ...          1456.908190          -1119.810009   \n",
       "19998        158.367103  ...          1456.902648          -1117.184313   \n",
       "19999        240.170676  ...          1457.021201          -1114.571229   \n",
       "\n",
       "       HT_Hp_0.1_pcc  HT_Hp_0.01_weight  HT_Hp_0.01_mean  HT_Hp_0.01_std  \\\n",
       "0           0.000000           1.000000        54.000000        0.000000   \n",
       "1           0.000000           1.000000        96.000000        0.000000   \n",
       "2           0.000000           1.999999        91.499997       20.250000   \n",
       "3           0.000000           1.000000        75.000000        0.000000   \n",
       "4           0.000000           1.000000        84.000000        0.000000   \n",
       "...              ...                ...              ...             ...   \n",
       "19995      -0.090714          76.962076        64.486558     4025.863982   \n",
       "19996      -0.091074          77.961908        64.352049     3975.617564   \n",
       "19997      -0.091428          78.961793        64.220947     3926.608927   \n",
       "19998      -0.091777          79.961713        64.093124     3878.792948   \n",
       "19999      -0.091750         245.922117      1454.547179    40191.099793   \n",
       "\n",
       "       HT_Hp_0.01_radius  HT_Hp_0.01_magnitude  HT_Hp_0.01_covariance  \\\n",
       "0               0.000000             54.000000               0.000000   \n",
       "1               0.000000             96.000000               0.000000   \n",
       "2              20.250000             91.499997               0.000000   \n",
       "3              20.250000            118.309972               0.000000   \n",
       "4               0.000000             84.000000               0.000000   \n",
       "...                  ...                   ...                    ...   \n",
       "19995       40551.972963           1455.855829           -4200.761291   \n",
       "19996       40547.015494           1455.849877           -4188.699383   \n",
       "19997       40542.239555           1455.844088           -4176.699969   \n",
       "19998       40537.636403           1455.838455           -4164.762776   \n",
       "19999       40377.834728           1455.958593           -4152.895061   \n",
       "\n",
       "       HT_Hp_0.01_pcc  \n",
       "0            0.000000  \n",
       "1            0.000000  \n",
       "2            0.000000  \n",
       "3            0.000000  \n",
       "4            0.000000  \n",
       "...               ...  \n",
       "19995       -0.329585  \n",
       "19996       -0.330709  \n",
       "19997       -0.331813  \n",
       "19998       -0.332898  \n",
       "19999       -0.332612  \n",
       "\n",
       "[20000 rows x 100 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0]\n",
      "The gradient with respect to 10 is 20.0\n",
      "The gradients with respect to each binary digit of 10 are [0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def binary_gradient(n):\n",
    "    # Convert n to binary and reverse it\n",
    "    binary = list(map(int, bin(n)[2:]))[::-1]\n",
    "\n",
    "    # Convert each digit to a PyTorch tensor\n",
    "    binary_tensors = [torch.tensor(float(b), requires_grad=True) for b in binary]\n",
    "\n",
    "    # Compute the value of n as a function of the binary digits\n",
    "    n_tensor = sum(b * 2**i for i, b in enumerate(binary_tensors))\n",
    "\n",
    "    # Detach n_tensor from the computation graph and set requires_grad=True\n",
    "    n_tensor = n_tensor.detach().requires_grad_(True)\n",
    "\n",
    "    # Define the function\n",
    "    f = n_tensor ** 2\n",
    "\n",
    "    # Compute the gradient with respect to n\n",
    "    f.backward()\n",
    "\n",
    "    # The gradient with respect to n\n",
    "    n_grad = n_tensor.grad.item()\n",
    "\n",
    "    # The gradient with respect to each binary digit\n",
    "    # binary_grads = [b.grad.item() for b in binary_tensors]\n",
    "    binary_grads = [b.grad.item() if b.grad is not None else 0 for b in binary_tensors]\n",
    "    print(binary_grads)\n",
    "\n",
    "    return n_grad, binary_grads\n",
    "\n",
    "# Use the function\n",
    "n = 10\n",
    "n_grad, binary_grads = binary_gradient(n)\n",
    "print(f\"The gradient with respect to {n} is {n_grad}\")\n",
    "print(f\"The gradients with respect to each binary digit of {n} are {binary_grads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Wireshark is installed, but cannot read manuf !\n"
     ]
    }
   ],
   "source": [
    "# read the pcap file\n",
    "import scapy.all as scapy\n",
    "import pandas as pd\n",
    "\n",
    "PCAP_PATH = \"../../data/malicious/Port_Scanning_SmartTV.pcap\"\n",
    "# Read the pcap file\n",
    "packets = scapy.rdpcap(PCAP_PATH)\n",
    "\n",
    "# crop to first 500 packets\n",
    "packets = packets[:500]\n",
    "\n",
    "# save pcap file\n",
    "scapy.wrpcap(\"../../data/malicious/Port_Scanning_SmartTV_500.pcap\", packets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
